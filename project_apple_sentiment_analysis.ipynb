{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "090eb1b0",
   "metadata": {},
   "source": [
    "# Preprocessing and understanding the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac544bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mechanize\n",
      "  Downloading mechanize-0.4.7-py2.py3-none-any.whl (109 kB)\n",
      "\u001b[K     |████████████████████████████████| 109 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: html5lib>=0.999999999 in /opt/anaconda3/lib/python3.8/site-packages (from mechanize) (1.1)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.8/site-packages (from html5lib>=0.999999999->mechanize) (0.5.1)\n",
      "Requirement already satisfied: six>=1.9 in /opt/anaconda3/lib/python3.8/site-packages (from html5lib>=0.999999999->mechanize) (1.15.0)\n",
      "Installing collected packages: mechanize\n",
      "Successfully installed mechanize-0.4.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mechanize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "e00f8c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "from mechanize import Browser\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "8c2b39f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Apple-Twitter-Sentiment-DFE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "3b5abe3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3886, 12)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "2ec9328d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment:confidence</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>623495513</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6264</td>\n",
       "      <td>Mon Dec 01 19:30:03 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>3\\nnot_relevant</td>\n",
       "      <td>#AAPL:The 10 best Steve Jobs emails ever...htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>623495514</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8129</td>\n",
       "      <td>Mon Dec 01 19:43:51 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>3\\n1</td>\n",
       "      <td>RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>623495515</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Mon Dec 01 19:50:28 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>3</td>\n",
       "      <td>My cat only chews @apple cords. Such an #Apple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>623495516</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5848</td>\n",
       "      <td>Mon Dec 01 20:26:34 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>3\\n1</td>\n",
       "      <td>I agree with @jimcramer that the #IndividualIn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>623495517</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12-12-2014 12:14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6474</td>\n",
       "      <td>Mon Dec 01 20:29:33 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nobody expects the Spanish Inquisition #AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  623495513     True      golden                  10               NaN   \n",
       "1  623495514     True      golden                  12               NaN   \n",
       "2  623495515     True      golden                  10               NaN   \n",
       "3  623495516     True      golden                  17               NaN   \n",
       "4  623495517    False   finalized                   3  12-12-2014 12:14   \n",
       "\n",
       "  sentiment  sentiment:confidence                            date  \\\n",
       "0         3                0.6264  Mon Dec 01 19:30:03 +0000 2014   \n",
       "1         3                0.8129  Mon Dec 01 19:43:51 +0000 2014   \n",
       "2         3                1.0000  Mon Dec 01 19:50:28 +0000 2014   \n",
       "3         3                0.5848  Mon Dec 01 20:26:34 +0000 2014   \n",
       "4         3                0.6474  Mon Dec 01 20:29:33 +0000 2014   \n",
       "\n",
       "             id            query   sentiment_gold  \\\n",
       "0  5.400000e+17  #AAPL OR @Apple  3\\nnot_relevant   \n",
       "1  5.400000e+17  #AAPL OR @Apple             3\\n1   \n",
       "2  5.400000e+17  #AAPL OR @Apple                3   \n",
       "3  5.400000e+17  #AAPL OR @Apple             3\\n1   \n",
       "4  5.400000e+17  #AAPL OR @Apple              NaN   \n",
       "\n",
       "                                                text  \n",
       "0  #AAPL:The 10 best Steve Jobs emails ever...htt...  \n",
       "1  RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...  \n",
       "2  My cat only chews @apple cords. Such an #Apple...  \n",
       "3  I agree with @jimcramer that the #IndividualIn...  \n",
       "4       Nobody expects the Spanish Inquisition #AAPL  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "668aa689",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['sentiment'].unique()\n",
    "text_df = dataset.loc[:, ['sentiment', 'text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2174569e",
   "metadata": {},
   "source": [
    "we will remove the tweets for which the sentiment is non relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "1227f642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3804, 2)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = text_df[text_df['sentiment'] != 'not_relevant']\n",
    "text_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "81cd1bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    object\n",
       "text         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "505fed3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       #AAPL:The 10 best Steve Jobs emails ever...htt...\n",
       "1       RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...\n",
       "2       My cat only chews @apple cords. Such an #Apple...\n",
       "3       I agree with @jimcramer that the #IndividualIn...\n",
       "4            Nobody expects the Spanish Inquisition #AAPL\n",
       "                              ...                        \n",
       "3881    (Via FC) Apple Is Warming Up To Social Media -...\n",
       "3882    RT @MMLXIV: there is no avocado emoji may I as...\n",
       "3883    @marcbulandr I could not agree more. Between @...\n",
       "3884    My iPhone 5's photos are no longer downloading...\n",
       "3885    RT @SwiftKey: We're so excited to be named to ...\n",
       "Name: text, Length: 3804, dtype: object"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9012ff6",
   "metadata": {},
   "source": [
    "1. Remove the html, @, RT, AAPL, Apple, punctuation from all the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "94f20f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('@([A-Za-z0-9]+)', '', text)\n",
    "    text = re.sub('RT (@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub('aapl', '', text)\n",
    "    text = re.sub('apple', '', text)\n",
    "    text = re.sub('rt', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "c9b5b005",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df['text'] = text_df['text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406a4063",
   "metadata": {},
   "source": [
    "2. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "457c95e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "129dfb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df['text'] = text_df['text'].apply(lambda x: tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "61561f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  [the, best, steve, jobs, emails, ever]\n",
       "1           [why, stock, had, a, miniflash, crash, today]\n",
       "2           [my, cat, only, chews, cords, such, an, snob]\n",
       "3       [i, agree, with, that, the, individualinvestor...\n",
       "4            [nobody, expects, the, spanish, inquisition]\n",
       "                              ...                        \n",
       "3881    [via, fc, is, warming, up, to, social, media, ...\n",
       "3882    [there, is, no, avocado, emoji, may, i, ask, why]\n",
       "3883    [i, could, not, agree, more, between, and, onl...\n",
       "3884    [my, iphone, photos, are, no, longer, download...\n",
       "3885    [were, so, excited, to, be, named, to, s, app,...\n",
       "Name: text, Length: 3804, dtype: object"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a55f35",
   "metadata": {},
   "source": [
    "3. Removing stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "7dd77c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_stop_words(text):\n",
    "    word_list = [word for word in text if word not in stopwords.words('english')]\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "e1689bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df['text'] = text_df['text'].apply(lambda x: remove_stop_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce24f5ac",
   "metadata": {},
   "source": [
    "4. Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "055a1f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(text):\n",
    "    lemmatized_list = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemmatized_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "9205305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df['text'] = text_df['text'].apply(lambda x: lemmatize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "2e2f6c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         [best, steve, job, email, ever]\n",
       "1                        [stock, miniflash, crash, today]\n",
       "2                                 [cat, chew, cord, snob]\n",
       "3       [agree, individualinvestor, trade, extended, t...\n",
       "4                 [nobody, expects, spanish, inquisition]\n",
       "                              ...                        \n",
       "3881    [via, fc, warming, social, medium, hiring, soc...\n",
       "3882                           [avocado, emoji, may, ask]\n",
       "3883    [could, agree, great, thing, happen, andibm, i...\n",
       "3884    [iphone, photo, longer, downloading, automatic...\n",
       "3885       [excited, named, app, store, best, list, year]\n",
       "Name: text, Length: 3804, dtype: object"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7994b587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
